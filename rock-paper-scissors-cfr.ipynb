{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving Rock-Paper-Scissors using CFR\n",
    "\n",
    "Paper: http://modelai.gettysburg.edu/2013/cfr/cfr.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACTIONS = 3 # 3 Actions, R, P, S\n",
    "ROCK = 0\n",
    "PAPER = 1\n",
    "SCISSORS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick mixed action according to probability given\n",
    "def get_action(strategy):\n",
    "    return np.random.choice(np.arange(NUM_ACTIONS), p=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rock-Paper-Scissors Player class\n",
    "class RPSPlayer:\n",
    "    # Can initialize with given strategy\n",
    "    def __init__(self, strategy_sum=np.zeros(NUM_ACTIONS)):\n",
    "        self.regret_sum = np.zeros(NUM_ACTIONS) # Cumulative regret table, 0, 0, 0 for R, P, S\n",
    "        self.strategy_sum = strategy_sum # Cumulative strategy table\n",
    "\n",
    "    # Trains given number of iterations, by calculating utility, updating sum values.\n",
    "    def self_train(self, opponent_strategy, iterations=10000):\n",
    "        action_utility = np.zeros(NUM_ACTIONS)\n",
    "        for _ in range(iterations):\n",
    "            strategy = self.get_strategy()\n",
    "            self_action = get_action(strategy)\n",
    "            opponent_action = get_action(opponent_strategy)\n",
    "            \n",
    "            action_utility[opponent_action] = 0;\n",
    "            action_utility[(opponent_action + 1) % 3] = 1\n",
    "            action_utility[(opponent_action - 1) % 3] = -1\n",
    "\n",
    "            for action in range(NUM_ACTIONS):\n",
    "                self.regret_sum[action] += action_utility[action] - action_utility[self_action]\n",
    "\n",
    "    # Gets strategy based on regret sum table\n",
    "    def get_strategy(self):\n",
    "        strategy = np.zeros(NUM_ACTIONS) # Strategy table\n",
    "        normalizing_sum = 0\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            strategy[action] = self.regret_sum[action] if (self.regret_sum[action] > 0) else 0\n",
    "            normalizing_sum += strategy[action]\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                strategy[action] /= normalizing_sum\n",
    "            else:\n",
    "                strategy[action] = 1.0 / NUM_ACTIONS\n",
    "            self.strategy_sum[action] += strategy[action]\n",
    "        return strategy\n",
    "\n",
    "    # Total average strategy, to be used after minimizing regret over many iterations.\n",
    "    # Uses strategy_sum to normalize, instead of regret_sum\n",
    "    def get_average_strategy(self):\n",
    "        average_strategy = np.zeros(NUM_ACTIONS)\n",
    "        normalizing_sum = sum(self.strategy_sum)\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                average_strategy[action] = self.strategy_sum[action] / normalizing_sum\n",
    "            else:\n",
    "                average_strategy[action] = 1.0 / NUM_ACTIONS\n",
    "        return average_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to print strategy nicely\n",
    "def format_strategy(strategy):\n",
    "    return \"Rock %: \" + str(strategy[0]) + \"\\nPaper %: \" + str(strategy[1]) + \"\\nScissors %: \" + str(strategy[2]) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial strategies:\n",
      "\n",
      "Player 1:\n",
      " Rock %: 0.6393915768472631\n",
      "Paper %: 0.041171115761381764\n",
      "Scissors %: 0.31943730739135523\n",
      "\n",
      "Player 2:\n",
      " Rock %: 0.5643345431415068\n",
      "Paper %: 0.13211443878454807\n",
      "Scissors %: 0.3035510180739453\n",
      "\n",
      "----- After 0 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.43535274783797656\n",
      "Paper %: 0.23594592747601614\n",
      "Scissors %: 0.32870132468600727\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.41033373660272443\n",
      "Paper %: 0.2662603684837382\n",
      "Scissors %: 0.3234058949135373\n",
      "\n",
      "----- After 10 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.20171267725422887\n",
      "Paper %: 0.20468859923600213\n",
      "Scissors %: 0.593598723509769\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.39844932796267424\n",
      "Paper %: 0.3390774393674441\n",
      "Scissors %: 0.26247323266988165\n",
      "\n",
      "----- After 100 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.37207844356837316\n",
      "Paper %: 0.2746400072734566\n",
      "Scissors %: 0.35328154915817017\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.2464188840579309\n",
      "Paper %: 0.40055576629345413\n",
      "Scissors %: 0.35302534964861504\n",
      "\n",
      "----- After 1000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.31483347442350884\n",
      "Paper %: 0.3469667995194064\n",
      "Scissors %: 0.33819972605708476\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.3537046664768795\n",
      "Paper %: 0.28644479284530033\n",
      "Scissors %: 0.3598505406778202\n",
      "\n",
      "----- After 10000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.34410567346479753\n",
      "Paper %: 0.320074091915961\n",
      "Scissors %: 0.33582023461924154\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.32779336886986454\n",
      "Paper %: 0.33126342194916797\n",
      "Scissors %: 0.3409432091809675\n",
      "\n",
      "----- After 100000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.3346247958005811\n",
      "Paper %: 0.3316101735247855\n",
      "Scissors %: 0.3337650306746335\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.33256447047940574\n",
      "Paper %: 0.3353195353413883\n",
      "Scissors %: 0.332115994179206\n",
      "\n",
      "----- After 500000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.33318338965336375\n",
      "Paper %: 0.33274384983935995\n",
      "Scissors %: 0.3340727605072763\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.3343086842571057\n",
      "Paper %: 0.33365959400999434\n",
      "Scissors %: 0.3320317217329\n",
      "\n",
      "----- After 1000000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.33257688913190536\n",
      "Paper %: 0.3332747345600777\n",
      "Scissors %: 0.33414837630801697\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.33377835209458695\n",
      "Paper %: 0.3332515897580396\n",
      "Scissors %: 0.33297005814737346\n",
      "\n",
      "----- After 2000000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.3338016258569071\n",
      "Paper %: 0.33243529679473804\n",
      "Scissors %: 0.33376307734835475\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.3330928659437486\n",
      "Paper %: 0.33298255256190445\n",
      "Scissors %: 0.33392458149434695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise: RPS Equilibrium\n",
    "\n",
    "unbalanced_strategy = np.array([3, 4, 5])\n",
    "random_strategy = np.random.dirichlet(alpha=[1, 1, 1]) # Method to get random strategy (sums to 1)\n",
    "random_strategy2 = np.random.dirichlet(alpha=[1, 1, 1])\n",
    "player1 = RPSPlayer(random_strategy)\n",
    "player2 = RPSPlayer(random_strategy2)\n",
    "\n",
    "# Epoch #'s to print current strategies, to see as they develop\n",
    "data_points = (0, 10, 100, 1000, 10000, 100000, 500000, 1000000, 2000000)\n",
    "\n",
    "# View the initial strategies, before regret min\n",
    "print(\"Initial strategies:\\n\")\n",
    "print(\"Player 1:\\n\", format_strategy(player1.get_average_strategy()))\n",
    "print(\"Player 2:\\n\", format_strategy(player2.get_average_strategy()))\n",
    "\n",
    "for epoch in range(2000001):\n",
    "    # Set iterations to one in self training, so players can update after each.\n",
    "    # This minimizes magnitude of walk away from equilibrium, in this case (0.3-, 0.3-, 0.3-)\n",
    "    player2_strategy = player2.get_strategy()\n",
    "    player1.self_train(player2_strategy, iterations=1)\n",
    "    player1_strategy = player1.get_strategy()\n",
    "    player2.self_train(player1_strategy, iterations=1)\n",
    "    if epoch in data_points:\n",
    "        print(f\"----- After {epoch} iterations: ----- \\n\")\n",
    "        print(\"Player 1 Strategy:\\n\", format_strategy(player1.get_average_strategy()))\n",
    "        print(\"Player 2 Strategy:\\n\", format_strategy(player2.get_average_strategy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Colonel Blotto\n",
    "# Game with N battlefields, S soldiers. 2 Teams. Team that captures most battlefields wins.\n",
    "# A team captures a battlefield if they send more soldiers than the opponent.\n",
    "# A team can send any number of soldiers to each battlefield, including 0, but must sum < S.\n",
    "# Will be solving for N = 3, S = 5\n",
    "NUM_BATTLEFIELDS = 2\n",
    "NUM_SOLDIERS = 3\n",
    "\n",
    "# A Pure strategy would be any ordered set: (S1, S2, S3), Sum(S1-3) < 5, 0 <= Sn <= 5\n",
    "# This is any permutation of BBSSSSS, so 7 choose 2. 21 total pure strategies.\n",
    "NUM_ACTIONS = math.comb(NUM_BATTLEFIELDS + NUM_SOLDIERS - 1, NUM_BATTLEFIELDS - 1)\n",
    "\n",
    "\n",
    "ALL_STRATEGIES = combinations_with_replacement(range(NUM_BATTLEFIELDS), NUM_SOLDIERS)\n",
    "ALL_STRATEGIES = [list([combo.count(i) for i in range(NUM_BATTLEFIELDS)]) for combo in ALL_STRATEGIES]\n",
    "\n",
    "PURE_STRATEGIES = {count: strat for count, strat in enumerate(ALL_STRATEGIES)}\n",
    "\n",
    "# Method that returns the utility (-1, 0, 1) for strategy1\n",
    "def strategy_utility(strategy1, strategy2):\n",
    "    strategy1 = PURE_STRATEGIES[strategy1]\n",
    "    strategy2 = PURE_STRATEGIES[strategy2]\n",
    "    wins = 0\n",
    "    for battlefield in range(NUM_BATTLEFIELDS):\n",
    "        soldier_difference = strategy1[battlefield] - strategy2[battlefield]\n",
    "        if soldier_difference != 0:\n",
    "            wins += soldier_difference / abs(soldier_difference)\n",
    "    return wins if wins == 0 else wins / abs(wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# War Commander class\n",
    "class WarCommander:\n",
    "    # Can initialize with given strategy\n",
    "    def __init__(self, strategy_sum=np.zeros(NUM_ACTIONS)):\n",
    "        self.regret_sum = np.zeros(NUM_ACTIONS) # Cumulative regret table for each pure action\n",
    "        self.strategy_sum = strategy_sum # Cumulative strategy table\n",
    "\n",
    "    # Trains given number of iterations, by calculating utility, updating sum values.\n",
    "    def self_train(self, opponent_strategy, iterations=1):\n",
    "        action_utility = np.zeros(NUM_ACTIONS)\n",
    "        for _ in range(iterations):\n",
    "            strategy = self.get_strategy()\n",
    "            self_action = get_action(strategy)\n",
    "            opponent_action = get_action(opponent_strategy)\n",
    "\n",
    "            for action in range(NUM_ACTIONS):\n",
    "                action_utility[action] = strategy_utility(action, opponent_action)\n",
    "\n",
    "            for action in range(NUM_ACTIONS):\n",
    "                self.regret_sum[action] += action_utility[action] - action_utility[self_action]\n",
    "\n",
    "    # Gets strategy based on regret sum table\n",
    "    def get_strategy(self):\n",
    "        strategy = np.zeros(NUM_ACTIONS) # Strategy table\n",
    "        normalizing_sum = 0\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            strategy[action] = self.regret_sum[action] if (self.regret_sum[action] > 0) else 0\n",
    "            normalizing_sum += strategy[action]\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                strategy[action] /= normalizing_sum\n",
    "            else:\n",
    "                strategy[action] = 1.0 / NUM_ACTIONS\n",
    "            self.strategy_sum[action] += strategy[action]\n",
    "        return strategy\n",
    "\n",
    "    # Total average strategy, to be used after minimizing regret over many iterations.\n",
    "    # Uses strategy_sum to normalize, instead of regret_sum\n",
    "    def get_average_strategy(self):\n",
    "        average_strategy = np.zeros(NUM_ACTIONS)\n",
    "        normalizing_sum = sum(self.strategy_sum)\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                average_strategy[action] = self.strategy_sum[action] / normalizing_sum\n",
    "            else:\n",
    "                average_strategy[action] = 1.0 / NUM_ACTIONS\n",
    "        return average_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to print strategy nicely\n",
    "def format_strategy(strategy):\n",
    "    strStrat = ''\n",
    "    for num in range(NUM_ACTIONS):\n",
    "        if strategy[num] < 1/(NUM_ACTIONS * 2):\n",
    "            continue\n",
    "        else:\n",
    "            strStrat += 'Chance of playing: ' + str(PURE_STRATEGIES[num]) + ' is: %' + str(strategy[num]) + '\\n'\n",
    "    return strStrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial strategies:\n",
      "\n",
      "Player 1:\n",
      " Chance of playing: [2, 1] is: %0.5107274294947752\n",
      "Chance of playing: [0, 3] is: %0.3567486443787358\n",
      "\n",
      "Player 2:\n",
      " Chance of playing: [3, 0] is: %0.1983744598448869\n",
      "Chance of playing: [2, 1] is: %0.37013180346587815\n",
      "Chance of playing: [1, 2] is: %0.39364440537985546\n",
      "\n",
      "----- After 0 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.17092348428178186\n",
      "Chance of playing: [2, 1] is: %0.3369091431649251\n",
      "Chance of playing: [1, 2] is: %0.20658449109371438\n",
      "Chance of playing: [0, 3] is: %0.2855828814595786\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.2327914866149623\n",
      "Chance of playing: [2, 1] is: %0.29004393448862603\n",
      "Chance of playing: [1, 2] is: %0.2978814684599518\n",
      "Chance of playing: [0, 3] is: %0.17928311043645984\n",
      "\n",
      "----- After 10 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.23968567186284112\n",
      "Chance of playing: [2, 1] is: %0.261335975195425\n",
      "Chance of playing: [1, 2] is: %0.24433710753396276\n",
      "Chance of playing: [0, 3] is: %0.2546412454077711\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.24775541129760378\n",
      "Chance of playing: [2, 1] is: %0.25522312188982077\n",
      "Chance of playing: [1, 2] is: %0.25624540892955894\n",
      "Chance of playing: [0, 3] is: %0.2407760578830165\n",
      "\n",
      "----- After 100 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.24883138154111006\n",
      "Chance of playing: [2, 1] is: %0.2512843715738659\n",
      "Chance of playing: [1, 2] is: %0.24935839149399577\n",
      "Chance of playing: [0, 3] is: %0.2505258553910283\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.24974568699430974\n",
      "Chance of playing: [2, 1] is: %0.2505917822830831\n",
      "Chance of playing: [1, 2] is: %0.2507076079082751\n",
      "Chance of playing: [0, 3] is: %0.2489549228143319\n",
      "\n",
      "----- After 1000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.24988156288209953\n",
      "Chance of playing: [2, 1] is: %0.25013016846205427\n",
      "Chance of playing: [1, 2] is: %0.24993497427522773\n",
      "Chance of playing: [0, 3] is: %0.25005329438061846\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.24997422589108578\n",
      "Chance of playing: [2, 1] is: %0.2500599759378262\n",
      "Chance of playing: [1, 2] is: %0.2500717146307438\n",
      "Chance of playing: [0, 3] is: %0.24989408354034418\n",
      "\n",
      "----- After 10000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.24998814030159705\n",
      "Chance of playing: [2, 1] is: %0.2500130344163123\n",
      "Chance of playing: [1, 2] is: %0.2499934886503665\n",
      "Chance of playing: [0, 3] is: %0.2500053366317242\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.2499974191101257\n",
      "Chance of playing: [2, 1] is: %0.25000600568931985\n",
      "Chance of playing: [1, 2] is: %0.2500071811430975\n",
      "Chance of playing: [0, 3] is: %0.24998939405745685\n",
      "\n",
      "----- After 100000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.24999881387005615\n",
      "Chance of playing: [2, 1] is: %0.2500013036175932\n",
      "Chance of playing: [1, 2] is: %0.24999934877713473\n",
      "Chance of playing: [0, 3] is: %0.25000053373521586\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 0] is: %0.24999974187617105\n",
      "Chance of playing: [2, 1] is: %0.25000060065000757\n",
      "Chance of playing: [1, 2] is: %0.25000071821125375\n",
      "Chance of playing: [0, 3] is: %0.2499989392625676\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise: Colonel Blotto Equilibrium\n",
    "\n",
    "random_strategy = np.random.dirichlet(alpha=np.ones(NUM_ACTIONS)) # Method to get random strategy (sums to 1)\n",
    "random_strategy2 = np.random.dirichlet(alpha=np.ones(NUM_ACTIONS))\n",
    "player1 = WarCommander(random_strategy)\n",
    "player2 = WarCommander(random_strategy2)\n",
    "\n",
    "# Epoch #'s to print current strategies, to see as they develop\n",
    "data_points = (0, 10, 100, 1000, 10000, 100000, 500000, 1000000, 2000000)\n",
    "\n",
    "# View the initial strategies, before regret min\n",
    "print(\"Initial strategies:\\n\")\n",
    "print(\"Player 1:\\n\", format_strategy(player1.get_average_strategy()))\n",
    "print(\"Player 2:\\n\", format_strategy(player2.get_average_strategy()))\n",
    "\n",
    "for epoch in range(100001):\n",
    "    # Set iterations to one in self training, so players can update after each.\n",
    "    # This minimizes magnitude of walk away from equilibrium, in this case (0.3-, 0.3-, 0.3-)\n",
    "    player2_strategy = player2.get_strategy()\n",
    "    player1.self_train(player2_strategy, iterations=1)\n",
    "    player1_strategy = player1.get_strategy()\n",
    "    player2.self_train(player1_strategy, iterations=1)\n",
    "    if epoch in data_points:\n",
    "        print(f\"----- After {epoch} iterations: ----- \\n\")\n",
    "        print(\"Player 1 Strategy:\\n\", format_strategy(player1.get_average_strategy()))\n",
    "        print(\"Player 2 Strategy:\\n\", format_strategy(player2.get_average_strategy()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
