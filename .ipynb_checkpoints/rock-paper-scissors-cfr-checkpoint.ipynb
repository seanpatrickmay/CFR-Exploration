{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving Rock-Paper-Scissors using CFR\n",
    "\n",
    "Paper: http://modelai.gettysburg.edu/2013/cfr/cfr.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from itertools import combinations_with_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACTIONS = 3 # 3 Actions, R, P, S\n",
    "ROCK = 0\n",
    "PAPER = 1\n",
    "SCISSORS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick mixed action according to probability given\n",
    "def get_action(strategy):\n",
    "    return np.random.choice(np.arange(NUM_ACTIONS), p=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rock-Paper-Scissors Player class\n",
    "class RPSPlayer:\n",
    "    # Can initialize with given strategy\n",
    "    def __init__(self, strategy_sum=np.zeros(NUM_ACTIONS)):\n",
    "        self.regret_sum = np.zeros(NUM_ACTIONS) # Cumulative regret table, 0, 0, 0 for R, P, S\n",
    "        self.strategy_sum = strategy_sum # Cumulative strategy table\n",
    "\n",
    "    # Trains given number of iterations, by calculating utility, updating sum values.\n",
    "    def self_train(self, opponent_strategy, iterations=10000):\n",
    "        action_utility = np.zeros(NUM_ACTIONS)\n",
    "        for _ in range(iterations):\n",
    "            strategy = self.get_strategy()\n",
    "            self_action = get_action(strategy)\n",
    "            opponent_action = get_action(opponent_strategy)\n",
    "            \n",
    "            action_utility[opponent_action] = 0;\n",
    "            action_utility[(opponent_action + 1) % 3] = 1\n",
    "            action_utility[(opponent_action - 1) % 3] = -1\n",
    "\n",
    "            for action in range(NUM_ACTIONS):\n",
    "                self.regret_sum[action] += action_utility[action] - action_utility[self_action]\n",
    "\n",
    "    # Gets strategy based on regret sum table\n",
    "    def get_strategy(self):\n",
    "        strategy = np.zeros(NUM_ACTIONS) # Strategy table\n",
    "        normalizing_sum = 0\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            strategy[action] = self.regret_sum[action] if (self.regret_sum[action] > 0) else 0\n",
    "            normalizing_sum += strategy[action]\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                strategy[action] /= normalizing_sum\n",
    "            else:\n",
    "                strategy[action] = 1.0 / NUM_ACTIONS\n",
    "            self.strategy_sum[action] += strategy[action]\n",
    "        return strategy\n",
    "\n",
    "    # Total average strategy, to be used after minimizing regret over many iterations.\n",
    "    # Uses strategy_sum to normalize, instead of regret_sum\n",
    "    def get_average_strategy(self):\n",
    "        average_strategy = np.zeros(NUM_ACTIONS)\n",
    "        normalizing_sum = sum(self.strategy_sum)\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                average_strategy[action] = self.strategy_sum[action] / normalizing_sum\n",
    "            else:\n",
    "                average_strategy[action] = 1.0 / NUM_ACTIONS\n",
    "        return average_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to print strategy nicely\n",
    "def format_strategy(strategy):\n",
    "    return \"Rock %: \" + str(strategy[0]) + \"\\nPaper %: \" + str(strategy[1]) + \"\\nScissors %: \" + str(strategy[2]) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial strategies:\n",
      "\n",
      "Player 1:\n",
      " Rock %: 0.2256183852875299\n",
      "Paper %: 0.5776567715577962\n",
      "Scissors %: 0.196724843154674\n",
      "\n",
      "Player 2:\n",
      " Rock %: 0.016845839974561315\n",
      "Paper %: 0.4642607049720584\n",
      "Scissors %: 0.5188934550533802\n",
      "\n",
      "----- After 0 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.519650572873621\n",
      "Paper %: 0.30366336829704316\n",
      "Scissors %: 0.17668605882933577\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.22783750221374266\n",
      "Paper %: 0.37697579054624164\n",
      "Scissors %: 0.39518670724001564\n",
      "\n",
      "----- After 10 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.3882083908027014\n",
      "Paper %: 0.26086430407739203\n",
      "Scissors %: 0.3509273051199065\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.4293038563964095\n",
      "Paper %: 0.22791471664129723\n",
      "Scissors %: 0.3427814269622933\n",
      "\n",
      "----- After 100 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.3859682784097254\n",
      "Paper %: 0.2191536893335403\n",
      "Scissors %: 0.39487803225673423\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.37118528115143257\n",
      "Paper %: 0.2942602141651963\n",
      "Scissors %: 0.33455450468337117\n",
      "\n",
      "----- After 10000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Rock %: 0.3260148184096786\n",
      "Paper %: 0.3408265663941368\n",
      "Scissors %: 0.3331586151961845\n",
      "\n",
      "Player 2 Strategy:\n",
      " Rock %: 0.3254724658926074\n",
      "Paper %: 0.3385757143666152\n",
      "Scissors %: 0.33595181974077737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise: RPS Equilibrium\n",
    "\n",
    "unbalanced_strategy = np.array([3, 4, 5])\n",
    "random_strategy = np.random.dirichlet(alpha=[1, 1, 1]) # Method to get random strategy (sums to 1)\n",
    "random_strategy2 = np.random.dirichlet(alpha=[1, 1, 1])\n",
    "player1 = RPSPlayer(random_strategy)\n",
    "player2 = RPSPlayer(random_strategy2)\n",
    "\n",
    "# Epoch #'s to print current strategies, to see as they develop\n",
    "data_points = (0, 10, 100, 10000)\n",
    "\n",
    "# View the initial strategies, before regret min\n",
    "print(\"Initial strategies:\\n\")\n",
    "print(\"Player 1:\\n\", format_strategy(player1.get_average_strategy()))\n",
    "print(\"Player 2:\\n\", format_strategy(player2.get_average_strategy()))\n",
    "\n",
    "for epoch in range(100000):\n",
    "    # Set iterations to one in self training, so players can update after each.\n",
    "    # This minimizes magnitude of walk away from equilibrium, in this case (0.3-, 0.3-, 0.3-)\n",
    "    player2_strategy = player2.get_strategy()\n",
    "    player1.self_train(player2_strategy, iterations=1)\n",
    "    player1_strategy = player1.get_strategy()\n",
    "    player2.self_train(player1_strategy, iterations=1)\n",
    "    if epoch in data_points:\n",
    "        print(f\"----- After {epoch} iterations: ----- \\n\")\n",
    "        print(\"Player 1 Strategy:\\n\", format_strategy(player1.get_average_strategy()))\n",
    "        print(\"Player 2 Strategy:\\n\", format_strategy(player2.get_average_strategy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Colonel Blotto\n",
    "# Game with N battlefields, S soldiers. 2 Teams. Team that captures most battlefields wins.\n",
    "# A team captures a battlefield if they send more soldiers than the opponent.\n",
    "# A team can send any number of soldiers to each battlefield, including 0, but must sum < S.\n",
    "# Will be solving for N = 3, S = 5\n",
    "NUM_BATTLEFIELDS = 3\n",
    "NUM_SOLDIERS = 5\n",
    "\n",
    "# A Pure strategy would be any ordered set: (S1, S2, S3), Sum(S1-3) < 5, 0 <= Sn <= 5\n",
    "# This is any permutation of BBSSSSS, so 7 choose 2. 21 total pure strategies.\n",
    "NUM_ACTIONS = math.comb(NUM_BATTLEFIELDS + NUM_SOLDIERS - 1, NUM_BATTLEFIELDS - 1)\n",
    "\n",
    "\n",
    "ALL_STRATEGIES = combinations_with_replacement(range(NUM_BATTLEFIELDS), NUM_SOLDIERS)\n",
    "ALL_STRATEGIES = [list([combo.count(i) for i in range(NUM_BATTLEFIELDS)]) for combo in ALL_STRATEGIES]\n",
    "\n",
    "PURE_STRATEGIES = {count: strat for count, strat in enumerate(ALL_STRATEGIES)}\n",
    "\n",
    "# Method that returns the utility (-1, 0, 1) for strategy1\n",
    "def strategy_utility(strategy1, strategy2):\n",
    "    strategy1 = PURE_STRATEGIES[strategy1]\n",
    "    strategy2 = PURE_STRATEGIES[strategy2]\n",
    "    wins = 0\n",
    "    for battlefield in range(NUM_BATTLEFIELDS):\n",
    "        soldier_difference = strategy1[battlefield] - strategy2[battlefield]\n",
    "        if soldier_difference != 0:\n",
    "            wins += soldier_difference / abs(soldier_difference)\n",
    "    return wins if wins == 0 else wins / abs(wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# War Commander class\n",
    "class WarCommander:\n",
    "    # Can initialize with given strategy\n",
    "    def __init__(self, strategy_sum=np.zeros(NUM_ACTIONS)):\n",
    "        self.regret_sum = np.zeros(NUM_ACTIONS) # Cumulative regret table for each pure action\n",
    "        self.strategy_sum = strategy_sum # Cumulative strategy table\n",
    "\n",
    "    # Trains given number of iterations, by calculating utility, updating sum values.\n",
    "    def self_train(self, opponent_strategy, iterations=1):\n",
    "        action_utility = np.zeros(NUM_ACTIONS)\n",
    "        for _ in range(iterations):\n",
    "            strategy = self.get_strategy()\n",
    "            self_action = get_action(strategy)\n",
    "            opponent_action = get_action(opponent_strategy)\n",
    "\n",
    "            for action in range(NUM_ACTIONS):\n",
    "                action_utility[action] = strategy_utility(action, opponent_action)\n",
    "\n",
    "            for action in range(NUM_ACTIONS):\n",
    "                self.regret_sum[action] += action_utility[action] - action_utility[self_action]\n",
    "\n",
    "    # Gets strategy based on regret sum table\n",
    "    def get_strategy(self):\n",
    "        strategy = np.zeros(NUM_ACTIONS) # Strategy table\n",
    "        normalizing_sum = 0\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            strategy[action] = self.regret_sum[action] if (self.regret_sum[action] > 0) else 0\n",
    "            normalizing_sum += strategy[action]\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                strategy[action] /= normalizing_sum\n",
    "            else:\n",
    "                strategy[action] = 1.0 / NUM_ACTIONS\n",
    "            self.strategy_sum[action] += strategy[action]\n",
    "        return strategy\n",
    "\n",
    "    # Total average strategy, to be used after minimizing regret over many iterations.\n",
    "    # Uses strategy_sum to normalize, instead of regret_sum\n",
    "    def get_average_strategy(self):\n",
    "        average_strategy = np.zeros(NUM_ACTIONS)\n",
    "        normalizing_sum = sum(self.strategy_sum)\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                average_strategy[action] = self.strategy_sum[action] / normalizing_sum\n",
    "            else:\n",
    "                average_strategy[action] = 1.0 / NUM_ACTIONS\n",
    "        return average_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to print strategy nicely\n",
    "def format_strategy(strategy):\n",
    "    strStrat = ''\n",
    "    for num in range(NUM_ACTIONS):\n",
    "        if strategy[num] < 1/(NUM_ACTIONS * 2):\n",
    "            continue\n",
    "        else:\n",
    "            strStrat += 'Chance of playing: ' + str(PURE_STRATEGIES[num]) + ' is: %' + str(strategy[num]) + '\\n'\n",
    "    return strStrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial strategies:\n",
      "\n",
      "Player 1:\n",
      " Chance of playing: [3, 0, 2] is: %0.06532137461927304\n",
      "Chance of playing: [2, 3, 0] is: %0.07990176977132271\n",
      "Chance of playing: [2, 2, 1] is: %0.1535871643027135\n",
      "Chance of playing: [2, 1, 2] is: %0.03655802594277305\n",
      "Chance of playing: [2, 0, 3] is: %0.11159410028370344\n",
      "Chance of playing: [1, 3, 1] is: %0.06115838743617737\n",
      "Chance of playing: [1, 0, 4] is: %0.12911676964316685\n",
      "Chance of playing: [0, 5, 0] is: %0.02855516438884167\n",
      "Chance of playing: [0, 4, 1] is: %0.043103685649046326\n",
      "Chance of playing: [0, 3, 2] is: %0.12828665969984182\n",
      "Chance of playing: [0, 2, 3] is: %0.028734767944172963\n",
      "Chance of playing: [0, 0, 5] is: %0.038238088039908205\n",
      "\n",
      "Player 2:\n",
      " Chance of playing: [4, 1, 0] is: %0.07191511403289813\n",
      "Chance of playing: [4, 0, 1] is: %0.03720438422773986\n",
      "Chance of playing: [3, 2, 0] is: %0.08899512684649585\n",
      "Chance of playing: [2, 3, 0] is: %0.028314959562736733\n",
      "Chance of playing: [2, 2, 1] is: %0.042363899039388\n",
      "Chance of playing: [2, 1, 2] is: %0.061207767887778\n",
      "Chance of playing: [1, 4, 0] is: %0.046676973231819914\n",
      "Chance of playing: [1, 2, 2] is: %0.06583404188817986\n",
      "Chance of playing: [1, 1, 3] is: %0.11193542818599812\n",
      "Chance of playing: [1, 0, 4] is: %0.044092783596269405\n",
      "Chance of playing: [0, 5, 0] is: %0.06799407954638156\n",
      "Chance of playing: [0, 4, 1] is: %0.08968073414949862\n",
      "Chance of playing: [0, 3, 2] is: %0.0427121042106534\n",
      "Chance of playing: [0, 2, 3] is: %0.025904545250397048\n",
      "Chance of playing: [0, 0, 5] is: %0.12120770909773801\n",
      "\n",
      "----- After 0 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [4, 1, 0] is: %0.10025097013657708\n",
      "Chance of playing: [3, 0, 2] is: %0.037646807412773556\n",
      "Chance of playing: [2, 3, 0] is: %0.042506939130123454\n",
      "Chance of playing: [2, 2, 1] is: %0.06706873730725371\n",
      "Chance of playing: [2, 1, 2] is: %0.02805902452060689\n",
      "Chance of playing: [2, 0, 3] is: %0.05307104930091703\n",
      "Chance of playing: [1, 3, 1] is: %0.03625914501840833\n",
      "Chance of playing: [1, 1, 3] is: %0.10237699584674842\n",
      "Chance of playing: [1, 0, 4] is: %0.05891193908740483\n",
      "Chance of playing: [0, 5, 0] is: %0.025391404002629764\n",
      "Chance of playing: [0, 4, 1] is: %0.03024091108936465\n",
      "Chance of playing: [0, 3, 2] is: %0.05863523577296315\n",
      "Chance of playing: [0, 2, 3] is: %0.10878460518774019\n",
      "Chance of playing: [0, 1, 4] is: %0.10486834769161374\n",
      "Chance of playing: [0, 0, 5] is: %0.028619045219651945\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [5, 0, 0] is: %0.032339389329162756\n",
      "Chance of playing: [4, 1, 0] is: %0.055717736423664455\n",
      "Chance of playing: [4, 0, 1] is: %0.04414749315527836\n",
      "Chance of playing: [3, 2, 0] is: %0.06141107402819703\n",
      "Chance of playing: [3, 1, 1] is: %0.032336673863452604\n",
      "Chance of playing: [3, 0, 2] is: %0.03394108534813951\n",
      "Chance of playing: [2, 3, 0] is: %0.04118435160027732\n",
      "Chance of playing: [2, 2, 1] is: %0.045867331425827745\n",
      "Chance of playing: [2, 1, 2] is: %0.05214862104195774\n",
      "Chance of playing: [2, 0, 3] is: %0.03606493261384572\n",
      "Chance of playing: [1, 4, 0] is: %0.047305022823305044\n",
      "Chance of playing: [1, 3, 1] is: %0.03590235366578876\n",
      "Chance of playing: [1, 2, 2] is: %0.05369071237542503\n",
      "Chance of playing: [1, 1, 3] is: %0.06905784114136444\n",
      "Chance of playing: [1, 0, 4] is: %0.04644362627812154\n",
      "Chance of playing: [0, 5, 0] is: %0.05441072492815893\n",
      "Chance of playing: [0, 4, 1] is: %0.061639609795864615\n",
      "Chance of playing: [0, 3, 2] is: %0.04598339981624955\n",
      "Chance of playing: [0, 2, 3] is: %0.040380880162830764\n",
      "Chance of playing: [0, 1, 4] is: %0.03787853873781026\n",
      "Chance of playing: [0, 0, 5] is: %0.07214860144527775\n",
      "\n",
      "----- After 10 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [4, 1, 0] is: %0.023945778713466585\n",
      "Chance of playing: [3, 2, 0] is: %0.06383199210476345\n",
      "Chance of playing: [3, 1, 1] is: %0.05417376114372897\n",
      "Chance of playing: [3, 0, 2] is: %0.11942136810937747\n",
      "Chance of playing: [2, 3, 0] is: %0.08844729281233062\n",
      "Chance of playing: [2, 2, 1] is: %0.06968304223131556\n",
      "Chance of playing: [2, 1, 2] is: %0.08378046409696341\n",
      "Chance of playing: [2, 0, 3] is: %0.10611231477387646\n",
      "Chance of playing: [1, 4, 0] is: %0.05132804566897702\n",
      "Chance of playing: [1, 3, 1] is: %0.05324203951041025\n",
      "Chance of playing: [1, 2, 2] is: %0.04579860753705047\n",
      "Chance of playing: [1, 1, 3] is: %0.09700649420964277\n",
      "Chance of playing: [0, 2, 3] is: %0.03472069729501927\n",
      "Chance of playing: [0, 1, 4] is: %0.034209881099872344\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [4, 1, 0] is: %0.06702217732414996\n",
      "Chance of playing: [3, 2, 0] is: %0.119797103751661\n",
      "Chance of playing: [3, 1, 1] is: %0.030880686072334875\n",
      "Chance of playing: [3, 0, 2] is: %0.03108995713555491\n",
      "Chance of playing: [2, 3, 0] is: %0.15439854908548398\n",
      "Chance of playing: [2, 1, 2] is: %0.028917126958686618\n",
      "Chance of playing: [2, 0, 3] is: %0.04638447194632419\n",
      "Chance of playing: [1, 2, 2] is: %0.06969797945145775\n",
      "Chance of playing: [1, 1, 3] is: %0.1229101170199619\n",
      "Chance of playing: [0, 3, 2] is: %0.034109969167627235\n",
      "Chance of playing: [0, 2, 3] is: %0.13724394003408955\n",
      "Chance of playing: [0, 1, 4] is: %0.04507180387953496\n",
      "\n",
      "----- After 100 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 2, 0] is: %0.06658655779156686\n",
      "Chance of playing: [3, 1, 1] is: %0.06016518836265356\n",
      "Chance of playing: [3, 0, 2] is: %0.08930801846571632\n",
      "Chance of playing: [2, 3, 0] is: %0.08779010117474609\n",
      "Chance of playing: [2, 2, 1] is: %0.04139936532525721\n",
      "Chance of playing: [2, 1, 2] is: %0.05482567375079444\n",
      "Chance of playing: [2, 0, 3] is: %0.08626098472661421\n",
      "Chance of playing: [1, 3, 1] is: %0.07540429620468948\n",
      "Chance of playing: [1, 2, 2] is: %0.06071417277989922\n",
      "Chance of playing: [1, 1, 3] is: %0.07380434854253562\n",
      "Chance of playing: [0, 4, 1] is: %0.028898005524920046\n",
      "Chance of playing: [0, 3, 2] is: %0.11972878957973225\n",
      "Chance of playing: [0, 2, 3] is: %0.10565655087888917\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 2, 0] is: %0.04098986094000947\n",
      "Chance of playing: [3, 1, 1] is: %0.031113114483229207\n",
      "Chance of playing: [3, 0, 2] is: %0.12188111392344787\n",
      "Chance of playing: [2, 3, 0] is: %0.13295104545592917\n",
      "Chance of playing: [2, 0, 3] is: %0.1529236892550684\n",
      "Chance of playing: [1, 3, 1] is: %0.09711313226912541\n",
      "Chance of playing: [1, 2, 2] is: %0.06810678946029772\n",
      "Chance of playing: [1, 1, 3] is: %0.07228224993068756\n",
      "Chance of playing: [0, 3, 2] is: %0.11429520135187839\n",
      "Chance of playing: [0, 2, 3] is: %0.07508788033251745\n",
      "\n",
      "----- After 1000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 2, 0] is: %0.09811361498036784\n",
      "Chance of playing: [3, 1, 1] is: %0.08601359350788856\n",
      "Chance of playing: [3, 0, 2] is: %0.10073240236943015\n",
      "Chance of playing: [2, 3, 0] is: %0.115475767093244\n",
      "Chance of playing: [2, 0, 3] is: %0.09634685595726245\n",
      "Chance of playing: [1, 3, 1] is: %0.09968068671934127\n",
      "Chance of playing: [1, 1, 3] is: %0.09462327532966544\n",
      "Chance of playing: [0, 3, 2] is: %0.13461251153383516\n",
      "Chance of playing: [0, 2, 3] is: %0.10045215925457952\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 2, 0] is: %0.09014332925124605\n",
      "Chance of playing: [3, 1, 1] is: %0.10647016392012601\n",
      "Chance of playing: [3, 0, 2] is: %0.12506775036768877\n",
      "Chance of playing: [2, 3, 0] is: %0.11357313747439575\n",
      "Chance of playing: [2, 0, 3] is: %0.08464707574188007\n",
      "Chance of playing: [1, 3, 1] is: %0.08284275066957075\n",
      "Chance of playing: [1, 1, 3] is: %0.1282743167125348\n",
      "Chance of playing: [0, 3, 2] is: %0.1474886821603858\n",
      "Chance of playing: [0, 2, 3] is: %0.10513900910516973\n",
      "\n",
      "----- After 10000 iterations: ----- \n",
      "\n",
      "Player 1 Strategy:\n",
      " Chance of playing: [3, 2, 0] is: %0.11055187091821397\n",
      "Chance of playing: [3, 1, 1] is: %0.11309184432227534\n",
      "Chance of playing: [3, 0, 2] is: %0.11149575400978833\n",
      "Chance of playing: [2, 3, 0] is: %0.12171282612639153\n",
      "Chance of playing: [2, 0, 3] is: %0.11294117346892987\n",
      "Chance of playing: [1, 3, 1] is: %0.09830977268423705\n",
      "Chance of playing: [1, 1, 3] is: %0.09976245611321219\n",
      "Chance of playing: [0, 3, 2] is: %0.1122197977771905\n",
      "Chance of playing: [0, 2, 3] is: %0.11242063682679379\n",
      "\n",
      "Player 2 Strategy:\n",
      " Chance of playing: [3, 2, 0] is: %0.08289979712214332\n",
      "Chance of playing: [3, 1, 1] is: %0.14245976289639214\n",
      "Chance of playing: [3, 0, 2] is: %0.10060057228326053\n",
      "Chance of playing: [2, 3, 0] is: %0.12088275937091249\n",
      "Chance of playing: [2, 0, 3] is: %0.09890453525480795\n",
      "Chance of playing: [1, 3, 1] is: %0.11260408712879762\n",
      "Chance of playing: [1, 1, 3] is: %0.12515919266900952\n",
      "Chance of playing: [0, 3, 2] is: %0.11089237337484027\n",
      "Chance of playing: [0, 2, 3] is: %0.10395933401032977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise: Colonel Blotto Equilibrium\n",
    "\n",
    "random_strategy = np.random.dirichlet(alpha=np.ones(NUM_ACTIONS)) # Method to get random strategy (sums to 1)\n",
    "random_strategy2 = np.random.dirichlet(alpha=np.ones(NUM_ACTIONS))\n",
    "player1 = WarCommander(random_strategy)\n",
    "player2 = WarCommander(random_strategy2)\n",
    "\n",
    "# Epoch #'s to print current strategies, to see as they develop\n",
    "data_points = (0, 10, 100, 1000, 10000)\n",
    "\n",
    "# View the initial strategies, before regret min\n",
    "print(\"Initial strategies:\\n\")\n",
    "print(\"Player 1:\\n\", format_strategy(player1.get_average_strategy()))\n",
    "print(\"Player 2:\\n\", format_strategy(player2.get_average_strategy()))\n",
    "\n",
    "for epoch in range(100001):\n",
    "    # Set iterations to one in self training, so players can update after each.\n",
    "    # This minimizes magnitude of walk away from equilibrium, in this case (0.3-, 0.3-, 0.3-)\n",
    "    player2_strategy = player2.get_strategy()\n",
    "    player1.self_train(player2_strategy, iterations=1)\n",
    "    player1_strategy = player1.get_strategy()\n",
    "    player2.self_train(player1_strategy, iterations=1)\n",
    "    if epoch in data_points:\n",
    "        print(f\"----- After {epoch} iterations: ----- \\n\")\n",
    "        print(\"Player 1 Strategy:\\n\", format_strategy(player1.get_average_strategy()))\n",
    "        print(\"Player 2 Strategy:\\n\", format_strategy(player2.get_average_strategy()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CFR Min Stars Here! Kuhn Poker First!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, some data definitions\n",
    "from sortedcontainers import SortedDict\n",
    "import random\n",
    "\n",
    "PASS = 0\n",
    "BET = 1\n",
    "NUM_ACTIONS = 2 # Bet, Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuhnNode:\n",
    "    def __init__(self):\n",
    "        self.infoSet = \"\"\n",
    "        self.regretSum = [0.0] * NUM_ACTIONS\n",
    "        self.strategy = [0.0] * NUM_ACTIONS\n",
    "        self.strategySum = [0.0] * NUM_ACTIONS\n",
    "\n",
    "    def getStrategy(self, realizationWeight):\n",
    "        normalizingSum = 0\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if self.regretSum[action] > 0:\n",
    "                self.strategy[action] = self.regretSum[action]\n",
    "            else:\n",
    "                self.strategy[action] = 0\n",
    "            normalizingSum += self.strategy[action]\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizingSum > 0:\n",
    "                self.strategy[action] /= normalizingSum\n",
    "            else:\n",
    "                self.strategy[action] = 1.0 / NUM_ACTIONS\n",
    "            self.strategySum[action] += realizationWeight * self.strategy[action]\n",
    "        return self.strategy\n",
    "\n",
    "    def getAverageStrategy(self):\n",
    "        averageStrategy = [0.0] * NUM_ACTIONS\n",
    "        normalizingSum = 0.0\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            normalizingSum += self.strategySum[action]\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            if normalizingSum > 0:\n",
    "                averageStrategy[action] = self.strategySum[action] / normalizingSum\n",
    "            else:\n",
    "                averageStrategy[action] = 1.0 / NUM_ACTIONS\n",
    "        return averageStrategy\n",
    "\n",
    "    def __str__(self):\n",
    "        avgStratsNice = [round(num, 4) for num in self.getAverageStrategy()]\n",
    "        return f\"{self.infoSet:>4}: Pass: {avgStratsNice[0]} Bet: {avgStratsNice[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfr(cards, history, p0, p1):\n",
    "    plays = len(history)\n",
    "    player = plays % 2\n",
    "    opponent = 1 - player\n",
    "\n",
    "    # Getting return payoffs for terminal states\n",
    "    if (plays > 1):\n",
    "        terminalPass = history[plays - 1] == 'p'\n",
    "        doubleBet = history[plays - 2 : plays] == (\"bb\")\n",
    "        isPlayerCardHigher = cards[player] > cards[opponent]\n",
    "        if terminalPass:\n",
    "            if history == (\"pp\"):\n",
    "                return 1 if isPlayerCardHigher else -1\n",
    "            else:\n",
    "                return 1\n",
    "        elif doubleBet:\n",
    "            return 2 if isPlayerCardHigher else -2\n",
    "\n",
    "    infoSet = str(cards[player]) + history\n",
    "\n",
    "    # Get info set node, or create it\n",
    "    node = nodeMap.get(infoSet)\n",
    "    if node == None:\n",
    "        node = KuhnNode()\n",
    "        node.infoSet = infoSet\n",
    "        nodeMap[infoSet] = node\n",
    "\n",
    "    # Recursively call cfr with additional history and probability for each action\n",
    "    strategy = node.getStrategy(p0 if player == 0 else p1)\n",
    "    util = [0.0] * NUM_ACTIONS\n",
    "    nodeUtil = 0\n",
    "    for action in range(NUM_ACTIONS):\n",
    "        nextHistory = history + (\"p\" if action == 0 else \"b\")\n",
    "        if player == 0:\n",
    "            util[action] = - cfr(cards, nextHistory, p0 * strategy[action], p1)\n",
    "        else:\n",
    "            util[action] = - cfr(cards, nextHistory, p0, p1 * strategy[action])\n",
    "        nodeUtil += strategy[action] * util[action]\n",
    "\n",
    "    # Compute and accumulate cfr for each action\n",
    "    for action in range(NUM_ACTIONS):\n",
    "        regret = util[action] - nodeUtil\n",
    "        node.regretSum[action] += (p1 if player == 0 else p0) * regret\n",
    "\n",
    "    return nodeUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuhnTrainer:\n",
    "    def __init__(self):\n",
    "        self.nodeMap = dict()\n",
    "    \n",
    "    def train(self, iterations):\n",
    "        cards = list(range(1, 10))\n",
    "        util = 0.0\n",
    "        for iteration in range(iterations):\n",
    "            random.shuffle(cards)\n",
    "            util += self.cfr(cards, \"\", 1, 1)\n",
    "        print(\"Average game value: \", util / iterations)\n",
    "        for node in sorted(self.nodeMap.values(), key=(lambda node: node.infoSet)):\n",
    "            print(node)\n",
    "\n",
    "    def cfr(self, cards, history, p0, p1):\n",
    "        plays = len(history)\n",
    "        player = plays % 2\n",
    "        opponent = 1 - player\n",
    "    \n",
    "        # Getting return payoffs for terminal states\n",
    "        if (plays > 1):\n",
    "            terminalPass = history[plays - 1] == 'p'\n",
    "            doubleBet = history[plays - 2 : plays] == (\"bb\")\n",
    "            isPlayerCardHigher = cards[player] > cards[opponent]\n",
    "            if terminalPass:\n",
    "                if history == (\"pp\"):\n",
    "                    return 1 if isPlayerCardHigher else -1\n",
    "                else:\n",
    "                    return 1\n",
    "            elif doubleBet:\n",
    "                return 2 if isPlayerCardHigher else -2\n",
    "    \n",
    "        infoSet = str(cards[player]) + history\n",
    "    \n",
    "        # Get info set node, or create it\n",
    "        node = self.nodeMap.get(infoSet)\n",
    "        if node == None:\n",
    "            node = KuhnNode()\n",
    "            node.infoSet = infoSet\n",
    "            self.nodeMap[infoSet] = node\n",
    "    \n",
    "        # Recursively call cfr with additional history and probability for each action\n",
    "        strategy = node.getStrategy(p0 if player == 0 else p1)\n",
    "        util = [0.0] * NUM_ACTIONS\n",
    "        nodeUtil = 0\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            nextHistory = history + (\"p\" if action == 0 else \"b\")\n",
    "            if player == 0:\n",
    "                util[action] = - self.cfr(cards, nextHistory, p0 * strategy[action], p1)\n",
    "            else:\n",
    "                util[action] = - self.cfr(cards, nextHistory, p0, p1 * strategy[action])\n",
    "            nodeUtil += strategy[action] * util[action]\n",
    "    \n",
    "        # Compute and accumulate cfr for each action\n",
    "        for action in range(NUM_ACTIONS):\n",
    "            regret = util[action] - nodeUtil\n",
    "            node.regretSum[action] += (p1 if player == 0 else p0) * regret\n",
    "    \n",
    "        return nodeUtil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average game value:  -0.06348452015938917\n",
      "   1: Pass: 0.7933 Bet: 0.2067\n",
      "  1b: Pass: 1.0 Bet: 0.0\n",
      "  1p: Pass: 0.0023 Bet: 0.9977\n",
      " 1pb: Pass: 1.0 Bet: 0.0\n",
      "   2: Pass: 0.4167 Bet: 0.5833\n",
      "  2b: Pass: 1.0 Bet: 0.0\n",
      "  2p: Pass: 0.6739 Bet: 0.3261\n",
      " 2pb: Pass: 1.0 Bet: 0.0\n",
      "   3: Pass: 0.9913 Bet: 0.0087\n",
      "  3b: Pass: 0.8022 Bet: 0.1978\n",
      "  3p: Pass: 0.9998 Bet: 0.0002\n",
      " 3pb: Pass: 0.7335 Bet: 0.2665\n",
      "   4: Pass: 0.9908 Bet: 0.0092\n",
      "  4b: Pass: 0.4392 Bet: 0.5608\n",
      "  4p: Pass: 1.0 Bet: 0.0\n",
      " 4pb: Pass: 0.3889 Bet: 0.6111\n",
      "   5: Pass: 1.0 Bet: 0.0\n",
      "  5b: Pass: 0.4526 Bet: 0.5474\n",
      "  5p: Pass: 0.9998 Bet: 0.0002\n",
      " 5pb: Pass: 0.3854 Bet: 0.6146\n",
      "   6: Pass: 0.8039 Bet: 0.1961\n",
      "  6b: Pass: 0.0004 Bet: 0.9996\n",
      "  6p: Pass: 0.0241 Bet: 0.9759\n",
      " 6pb: Pass: 0.0 Bet: 1.0\n",
      "   7: Pass: 0.326 Bet: 0.674\n",
      "  7b: Pass: 0.0 Bet: 1.0\n",
      "  7p: Pass: 0.0 Bet: 1.0\n",
      " 7pb: Pass: 0.0 Bet: 1.0\n",
      "   8: Pass: 0.0308 Bet: 0.9692\n",
      "  8b: Pass: 0.0 Bet: 1.0\n",
      "  8p: Pass: 0.0 Bet: 1.0\n",
      " 8pb: Pass: 0.0001 Bet: 0.9999\n",
      "   9: Pass: 0.4605 Bet: 0.5395\n",
      "  9b: Pass: 0.0 Bet: 1.0\n",
      "  9p: Pass: 0.0 Bet: 1.0\n",
      " 9pb: Pass: 0.0 Bet: 1.0\n"
     ]
    }
   ],
   "source": [
    "trainer = KuhnTrainer()\n",
    "trainer.train(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results for 1 million training iterations.\n",
    "\n",
    "It's very interesting to interpret the strategy.\n",
    "While the exercise in the paper was only for 3 cards, we can increase up to an arbitrary amount.\n",
    "\n",
    "Similar to real poker, you can see that bluffs tend to come from bottom of range, and the absolute top of range \"traps\" at a decent frequency, at least on the first action.\n",
    "\n",
    "In a similar game, with just one street, you would want to be bluffing 1/4 of the time, meaning you need 1 combo of bluff for every 2 combos of value. However, we can see that on the first street, we only have 0.8 combos of bluffs, coming from 1 and 2, whereas we have about 3.2 combos of value. This means we are bluffing 0.8/(0.8+3.2) = 0.8/4 = 1/5 of the time, less than the 1/4th called for.\n",
    "\n",
    "One reason this could be happening is that, with the existence of three streets, the implied odds artificially increase the size of the pot, so my 1/2 pot size bet (1 into a pot of 2) is actually smaller because of how large my bets will be in comparison to pot size later on. Having bluffs 1/5th of the time is appropriate for a 1/3 pot size bet, so we can approximate this to be the aritificial pot size accounting for future streets. Very cool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
